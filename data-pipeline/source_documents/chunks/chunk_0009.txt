Source: Training_For_AI_Engineer_Interns
Chunk 1 of 6
Size: 1435 characters
Hash: 1bf8a56f10c71cab6e3228a9a45f615591f92a587c9858354f2be99d527dd8b8
--------------------------------------------------
*  Generative AI in Nutshell - how to survive & thrive in the age of AI
      * Tokens: The numerical representation of text that LLMs read. A token generally corresponds to 4 characters of text for common English text. So based on the size, 100 tokens ~=75 words, using Â¾ rule. 
         * Understanding ChatGPT/OpenAI Tokens
      * Context Window: The number of tokens an LLM can receive at every
         * How context window work
      * Hallucinations: Wrong, made up, answers generated by LLMs
         * Why Large Language Models Hallucinate
      * Prompt Engineering: Ability to improve the way you ask questions to LLMs so that you get better results.
         * ChatGPT Prompt Engineering mini-course (1h)
         * Mini-course Prompt engineering for vision models
   * Advanced Prompting Techniques
   * Top-Players, Tools and Frameworks: OpenAI, Azure OpenAI, Anthropic, Hugging Face, Langchain, CrewAI, OpenAI's GPTs
   * Langchain Agents: AI bots able to use tools that allow them to access APIs, databases and more.
      * Langchain agents simply explained
   * Retrieval-Augmented Generation (RAG): 
      * No Code: Build a RAG System Using Claude 3 Opus And MongoDB
   * Conversational Agents: Group of AI agents able to assume roles and plan/discuss/validate answer before providing them.
      * Here is a lecture from Andrew Ng demonstrating the Agentic Workflows and why they are game-changer